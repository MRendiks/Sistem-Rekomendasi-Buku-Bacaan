# -*- coding: utf-8 -*-
"""MLT_Submission_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W5RMvtH1CBAcwQNEQ9UXv5wAtRBhzlf5

# **Sistem Rekomendasi**: Rekomendasi Buku yang Dibaca 
---
##### Oleh : [Yogi Dwi Andrian](https://www.dicoding.com/users/yogidwiandrian)
##### Proyek Submission 2 - Machine Learning Terapan Dicoding

# **Pendahuluan**

Pada proyek ini akan dibuat sistem rekomendasi buku untuk pembaca menggunakan *content-based filtering*. Untuk memudahkan navigasi gunakan menu *Table of Contents* di kanan atas Google Colaboratory.

# **1. Mengimpor pustaka/modul python yang dibutuhkan**
"""

# Memasang modul plotly & scikit-learn terbaru
!pip install -U plotly
!pip install -U scikit-learn

# Untuk visualisasi data
import plotly.graph_objs as go
import plotly.express as px
import plotly.figure_factory as ff
import missingno as msno
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

# Untuk pengolahan data
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer

# Untuk pembuatan sistem rekomendasi 
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import cosine_similarity

"""# **2. Menyiapkan Dataset**

## 2.1 Menyiapkan kredensial akun Kaggle
"""

# Sebelumnya unggah API kredensial dari kaggle yang bernama kaggle.json
# Membuat direktori bernama ".kaggle"
!mkdir ~/.kaggle

# Menyalin file kaggle.json ke direktori baru yaitu ".kaggle"
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""## 2.2 Mengunduh dan Menyiapkan Dataset

![goodbooks-10k](https://user-images.githubusercontent.com/56554261/137752814-979c7bf0-bddb-4923-bb3c-c2066b273d25.png)

Informasi Dataset :

Jenis | Keterangan
--- | ---
Sumber | [Kaggle Dataset : goodbooks-10k](https://www.kaggle.com/zygmunt/goodbooks-10k)
Lisensi | CC BY-SA 4.0
Kategori | Literatur
Rating Penggunaan | 8.2 (Gold)
Jenis dan Ukuran Berkas | CSV (43 MB)
Nama Berkas | book_tags.csv, books.csv, ratings.csv, sample_book.xml, tags.csv, to_read.csv
"""

# Mengunduh dataset menggunakan Kaggle
!kaggle datasets download -d zygmunt/goodbooks-10k

# Mengekstrak berkas zip yang baru di unduh
!unzip goodbooks-10k.zip

"""# **3. Pemahaman Data** ***(Data Understanding)***

## 3.1 Memuat semua data pada sebuah Dataframe menggunakan *pandas*
"""

# Memuat semua file csv ke data dataframe 
book_tags = pd.read_csv("book_tags.csv")
books = pd.read_csv("books.csv")
ratings = pd.read_csv("ratings.csv")
tags = pd.read_csv("tags.csv")
to_read = pd.read_csv("to_read.csv")

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>
Pada proyek ini kita akan mengeksplorasi beberapa variabel saja, antara lain: <code>book tags</code>, <code>books</code>, <code>rating</code>,  <code>tags</code>
</details>

## 3.2 Eksplorasi *Books* Variabel
"""

# pratinjau dataframe
books.head(3)

# Memuat informasi dataframe
books.info()

# Menghitung jumlah data kosong pada setiap kolom
books.isna().sum()

# Memvisualisasikan data kosong pada setiap kolom
sorted_books = msno.nullity_sort(books, sort='ascending') 
msno.matrix(sorted_books, color=(1, 0.3, 0.3))

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>

variabel <code>books.csv</code> berisi informasi mengenai detail dari buku. Namun pada datanya masih terdapat banyak sekali nilai kosong seperti pada kolom <code>isbn</code>, <code>isbn13</code>, <code>original_publication_year</code>, <code>original_title</code> dan <code>language_code</code> 

Kemudian berikut adalah uraian variabel dari setiap kolom pada data : 

1. Kolom <code>book_id</code> merupakan kolom id dari masing-masing buku.

2. Kolom <code>best_book_id</code> edisi paling populer untuk karya tertentu.

3. Kolom <code>work_id</code> mengacu pada buku dalam arti abstrak.

4. Kolom <code>books_count</code> merupakan kolom jumlah edisi untuk suatu karya tertentu.

5. Kolom <code>isbn</code> ISBN (International Standard Book Number) adalah kode pengidentifikasian buku yang bersifat unik.

6. Kolom <code>isbn13</code> sama dengan kolom isbn hanya saja isbn13 mempunyai 13 digit kode unik.

7. Kolom <code>authors</code> merupakan kolom nama dari penulis/pengarang buku.

8. Kolom <code>original_publication_year</code> berisi tahun penerbitan buku.

9. Kolom <code>original_title</code> merupakan kolom berisi judul buku.

10.  Kolom <code>title</code> merupakan kolom berisi judul buku dan hampir mirip dengan original title.

11.  Kolom <code>language_code</code> berisi kode bahasa buku

12.  Kolom <code>average_rating</code> merupakan kolom dari rata-rata rating buku.

13.  Kolom <code>ratings_count</code> berisi jumlah total pembaca yang memberikan rating.

14.  Kolom <code>work_ratings_count</code> tidak ada keterangan lebih lanjut mengenai kolom ini.

15.  Kolom <code>work_text_reviews_count</code> tidak ada keterangan lebih lanjut mengenai kolom ini.

16.  Kolom <code>ratings_1</code> kolom jumlah pembaca yang memberikan rating 1

17.  Kolom <code>ratings_2</code> kolom jumlah pembaca yang memberikan rating 2

18.  Kolom <code>ratings_3</code> kolom jumlah pembaca yang memberikan rating 3

19.  Kolom <code>ratings_4</code> kolom jumlah pembaca yang memberikan rating 4

20.  Kolom <code>ratings_5</code> kolom jumlah pembaca yang memberikan rating 5

21.  Kolom <code>image_url</code> berisi alamat gambar buku dengan ukuran normal

22.  Kolom <code>small_image_url</code> berisi alamat gambar buku dengan ukuran kecil
</details>

## 3.3 Eksplorasi *Ratings* Variabel
"""

# Memuat informasi dataframe
ratings.info()

# Menghitung jumlah data kosong pada setiap kolom
ratings.isna().sum()

# melihat distribusi rating pada data
ratings.describe()

print('Jumlah book_id: ', len(ratings.book_id.unique()))
print('Jumlah user_id: ', len(ratings.user_id.unique()))
print('Jumlah data rating: ', len(ratings))

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>

variabel <code>ratings.csv</code> berisi informasi mengenai rating yang diberikan oleh <i>user<i> terhadap masing-masing buku. Tidak ada data yang kosong pada semua kolom.

Kemudian berikut adalah uraian variabel dari setiap kolom pada data : 

1. Kolom <code>book_id</code> merupakan kolom id dari masing-masing buku.

2. Kolom <code>user_id</code> merupakan id atau identitas user.

3. Kolom <code>rating</code> jumlah rating yang diberikan untuk buku dari <i>user</i> yang berskala 1 hingga 5.
</details>

## 3.4 Eksplorasi *book_tags* Variabel
"""

# Menampilkan data pada dataframe
book_tags.head()

# Menghitung jumlah data kosong pada setiap kolom
book_tags.isna().sum()

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>

Berikut adalah uraian variabel dari setiap kolom pada data : 

1. Kolom <code>goodreads_book_id</code> menunjuk ke edisi yang paling populer dari sebuah buku yang diberikan.

2. Kolom <code>tag_id</code> merupakan id dari label atau kategori dari buku.

3. Kolom <code>count</code> jumlah buku yang ada pada label <i>tag_id</i>.
</details>

## 3.5 Eksplorasi *tags* Variabel
"""

# Menampilkan data pada dataframe
tags.tail()

# Menghitung jumlah data kosong pada setiap kolom
tags.isna().sum()

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>

Berisi pemetaan id dengan nama label/kategori

Berikut adalah uraian variabel dari setiap kolom pada data : 

1. Kolom <code>tag_id</code> merupakan id dari label atau kategori dari buku.

2. Kolom <code>tag_name</code> nama dari label atau kategori dari buku.
</details>

# **4. Persiapan Data** ***(Data Preparation)*** **dan Visualisasi Data**

## 4.1 Mengatasi data yang kosong
"""

# Menghitung jumlah data kosong pada setiap kolom
books.isna().sum()

books['original_title']= np.where(books['original_title'].isnull(), books['title'], books['original_title'])

# Menghitung jumlah data kosong pada setiap kolom
books.isna().sum()

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>
Sebelumnya kita sudah melihat pada data <i>understanding</i> bahwa hanya pada variabel `books` terdapat kolom yang kosong, maka kita harus mengisi data kosong tersebut. Disini kita hanya memanipulasi data pada <code>original tittle</code> dengan cara menyalin data pada <code>tittle</code> ke <code>original tittle</code> karena kedua kolom tersebut memiliki banyak kemiripan. Untuk kolom yang lain kita tidak melakukan manipulasi karena pada kolom lainnya merupakan kolom yang esensial bagi informasi buku dan nantinya kita tidak membutuhkan kolom tersebut.
</details>

## 4.2 Menghapus data yang duplikat
"""

# Melihat jumlah data duplikasi
print("Jumlah duplikat data books pada kolom original_title : ", books.duplicated(subset='original_title', keep=False).sum())
print("Jumlah duplikat data ratings pada kolom user_id, book_id : ", ratings.duplicated(subset =["user_id","book_id"], keep=False).sum())
print("Jumlah duplikat data tags pada kolom tag_id : ", tags.duplicated(subset='tag_id', keep=False).sum())
print("Jumlah duplikat data book_tags pada kolom tag_id, goodreads_book_id: ", book_tags.duplicated(subset=['tag_id','goodreads_book_id'], keep=False).sum())

print("Jumlah sebelum dihapus data duplikat ", ratings.shape)
ratings.drop_duplicates(subset = ["user_id","book_id"],keep = False, inplace = True) 
print("Jumlah sesudah dihapus data duplikat ", ratings.shape)

print("Jumlah sebelum dihapus data duplikat ", books.shape)
books.drop_duplicates(subset = 'original_title', keep=False, inplace=True)
print("Jumlah sesudah dihapus data duplikat ", books.shape)

print("Jumlah sebelum dihapus data duplikat ", book_tags.shape)
book_tags.drop_duplicates(subset = ['tag_id','goodreads_book_id'], keep=False, inplace=True)
print("Jumlah sesudah dihapus data duplikat ", book_tags.shape)

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>

Data duplikasi pada sistem rekomendasi dapat menyebabkan munculnya data yang sama sebanyak 2 kali atau lebih. Dengan demikian agar tidak terjadi hal tersebut, datanya dihapus saja karena sebenarnya data tersebut sudah ada pada dataframe.

</details>

## 4.3 Melakukan visualisasi data
"""

# Fungsi untuk plot distribusi data pada suatu kolom numerik
def top_books(column:str, title:str):
  top_books = books.sort_values(column, ascending=False)
  fig = px.bar(top_books[:10], x=column, y="original_title", title=title,
              orientation='h', color='original_title', width=1350, height=700)
  fig.show()

# Menampilkan visualisasi data top rated dan popular books
for column, tittle in ["average_rating","rated"], ["ratings_count", "popular"]:
    top_books(column=column, title=f"Top 10 {tittle} books")

top_popular = books.sort_values('average_rating', ascending=False)
tf_top_author = top_popular[:10]

fig = go.Figure(data=[go.Pie(labels=tf_top_author['authors'], values=tf_top_author['average_rating'],textinfo='label+value',hole=0.4)])
fig.update_layout(
title_text="Penulis Populer")
fig.show()

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>
Berdasarkan visualisasi penulis yang populer nama Bill Waterrson menempati peringkat pertama, dan yang menempati posisi kedua ialah J.K.Rowling dan dilanjutkan yang lainnya.
</details>
"""

# Menampilkan data distribusi numerik pada kolom average_rating
figures = px.histogram(data_frame=books,
                      x='average_rating',
                      color='average_rating',
                      template='plotly_white',
                      marginal='box',
                      nbins=200,
                      color_discrete_sequence=["#FF7171","#9FD8DF"],
                      barmode='stack',
                      histfunc='count')

figures.update_layout(font_family='Open Sans',
                      title=dict(text='Distribusi fitur numerik pada kolom average_rating',
                                x=0.47,
                                font=dict(color="#333",size=20)),
                      hoverlabel=dict(bgcolor='white'))

figures.show()

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>

Berdasarkan hasil visualisasi data diatas :

1. Untuk rata-rata rating tertinggi adalah 3.94

2. Untuk distribusi rating kebanyakan berada pada angka 3.5 sampai 4.5 

</details>

## 4.4 Ekstraksi fitur

### 4.4.1 Pemilihan data
"""

df = books[['original_title', 'authors']]
df.head()

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>

Karena kita akan membuat sistem rekomendasi berdasarkan penulis maka kita membuat <i>dataframe</i> baru dengan kolom nama buku dan penulisnya.

</details>

### 4.4.2 Mengubah data kedalam bentuk matriks menggunakan TF-IDF _Vectorizer_
"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data authors
tf.fit(df['authors'])

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(df['authors'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>

- Dikarenakan data kita dalam bentuk teks maka tidak bisa langsung dimasukkan pada pemodelan jadi untuk mengatasinya adalah dengan mengubah data teks menjadi numerik, disini kita menggunakan algoritma TF—IDF <i>Vectorizer</i> yang memberi bobot pada jumlah kata dengan ukuran seberapa sering kata tersebut muncul dalam dokumen.

- Pada `tfidf_matrix.shape` keluaran 9726 merupakan ukuran dari data dan 6151 merupakan matrik penulis buku.

- Setelah jadi vektor tf-idf maka agar dapat dimasukkan dalam model dirubah menjadi dalam bentuk matriks menggunakan fungsi `todense()`
</details>

# **5. Pembuatan Sistem Rekomendasi Content Based Filtering**

## 5.1 Dengan Cosine Similarity
"""

# Menghitung cosine similarity dari dataframe
cosine_sim = cosine_similarity(tfidf_matrix) 

# Menyimpan hasil perhitungan pada dataframe
cosine_sim_df = pd.DataFrame(cosine_sim, index=df['original_title'], columns=df['original_title'])

def getRecommendedBooks_cosine(book:str, recommended_books:int=5):
    print(f'Apabila pengguna menyukai buku {book}\n5 buku berikut ini juga mungkin akan disukai :')
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = cosine_sim_df.loc[:,book].to_numpy().argpartition(
        range(-1, -recommended_books, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = cosine_sim_df.columns[index[-1:-(recommended_books+2):-1]]
    
    # Drop book agar buku yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(book, errors='ignore')
    # Mengembalikan sebuah dataframe berupa rekomendasi terhadap buku
    return pd.DataFrame(closest).merge(df[['original_title', 'authors']]).head(recommended_books)

# Memberikan rekomendasi terhadap buku yang serupa
getRecommendedBooks_cosine("Harry Potter and the Prisoner of Azkaban")

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>
Dengan model  cosine similarity, dimana K = 5. Kita dapat melihat hasil rekomendasinya terhadap suatu judul buku. Bila dilihat secara seksama, hasilnya sangat baik dan relevan.
</details>

## 5.2 Dengan model K-Nearest Neighbor
"""

# Membuat sistem rekomendasi dengan model K-Nearest Neighbor
# Inisiasi model 
model = NearestNeighbors(metric='euclidean', )

# Melakukan fitting model terhadap data
model.fit(tfidf_matrix)

def getRecommendedBooks_knn(book:str, recommended_books:int=5):
    print(f'Apabila pengguna menyukai buku {book}\n5 buku berikut ini juga mungkin akan disukai :')
    # Mengambil data baris yang sama dengan judul buku
    # Mengubah data menjadi matriks
    df_book = df[df['original_title'] == book]
    book_matrix = tf.transform(df_book['authors'])
    book_matrix.todense()
    # Mencari buku terdekat dengan aplikasi yang disukai pembaca
    distances, indices = model.kneighbors(book_matrix, n_neighbors=recommended_books+1)
    book_similiar = pd.Series(indices.flatten()).map(df.reset_index()['original_title'])
    # Menampilkan penulis berdasarkan data buku terdekat yang didapat
    author = map(lambda x: df[df.original_title== x ].authors.item(), book_similiar)
    # Mengembalikan sebuah dataframe berupa rekomendasi terhadap buku dengan melewati index pertama
    result = pd.DataFrame({'Nama Buku':book_similiar, 'Penulis':author, 'Jarak':distances.flatten()})
    return result[1:]

# Memberikan rekomendasi terhadap buku yang serupa
getRecommendedBooks_knn("Harry Potter and the Prisoner of Azkaban")

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>
  Tidak jauh berbeda dengan model cosine similarity, pada model knn juga mendapatkan hasil yang baik dan relevan.
</details>

# **6. Evaluasi Cosine Similarity**

Dikarenakan hasilnya hampir mirip pada keduanya, maka diputuskan untuk mengevaluasi hasil dari _cosine similarity_

Keterangan rumus evaluasi yang digunakan:

![TP, TN, FP, FN](https://user-images.githubusercontent.com/56554261/137361455-47b803b1-dd3e-4c16-b1e2-ebc7e41e5dd9.png)

## 6.1 Evaluasi manual skor precision

Rumus:

![rumus _precision_](https://user-images.githubusercontent.com/56554261/137361550-a4a9e9ce-560d-4f3a-b89d-eb853d531bcc.png)
"""

# Rumus Presisi adalah rekomendasi yang relevan/item yang kami rekomendasikan.
rec_relevant = 5
item_recomend = 5
presisi = rec_relevant/item_recomend
print(f"Jadi nilai presisinya adalah {presisi*100}%")

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>
Dari hasil rekomendasi model, diketahui bahwa buku yang berjudul Harry Potter and the Prisoner of Azkaban ditulis oleh J.K. Rowling dan Mary GrandPré . Dari 5 buku yang direkomendasikan, semuanya memiliki penulis yang sama <i>(similar)</i>. Artinya, precision sistem kita sebesar 5/5 atau 100%.
</details>

## 6.2 Evaluasi manual skor akurasi

Rumus:

![rumus akurasi](https://user-images.githubusercontent.com/56554261/137361306-a5b54a6c-9dbe-4c84-a2b4-2f6ad9d1316d.png)
"""

# Rumus Akurasi = (TP + TN ) / (TP+FP+FN+TN)
tp = 5
tn = 0
fp = 0
fn = 0

akurasi = (tp+tn)/(tp+fp+fn+tn)
print(f"Jadi nilai akurasinya adalah {akurasi*100}%")

"""<details>
  <summary>Buka untuk penjelasan<h4><b>Penjelasan :</b></h4></summary>
Untuk hasil Akurasinya mirip dengan presisi yaitu 100% dari perhitungan hasil model.
</details>

# Penutupan

Model untuk memberikan rekomendasi buku untuk pembaca  telah selesai dibuat. Setelah diujikan, model ini bekerja cukup baik dalam memberikan 5 rekomendasi buku terhadap penulis yang disukai pembaca.


### Referensi
- Dokumentasi Scikit-learn : https://scikit-learn.org/stable/modules/classes.html
- Dokumentasi Plotly : https://plotly.com/python/
- Lainnya :
  - https://www.kaggle.com/bshirude2/goodreads-content-based-book-recommendation
  - https://www.kaggle.com/niharika41298/netflix-vs-books-recommender-analysis-eda#2.-Collaborative-Filtering
  - https://www.kaggle.com/nayansakhiya/books-visualisation-and-recommendation#3.-content-based-recommondation
"""